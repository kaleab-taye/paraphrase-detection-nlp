{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"cENw5aD5sk_B"},"source":["# Paraphrase Detection - NLP Course Assignment\n","\n","## created by : \n","- Kaleab Taye - UGR/0490/12\n","- Estifanos Neway - UGR/4776/12\n","- Beka Dessalegn - UGR/4605/12\n","\n","## Description\n","In this project we have attempted to build and train a model that determine whether two given text entities, such as sentences, convey the same meaning in different words. In order to obtain the paraphrase detection capablity we have tried to implement Bidirectional Long Short-Term Memory (Bi-LSTM) algorithm. The model is designed to analyze both syntactic and semantic features of input text pairs, providing a robust solution to the paraphrase detection challenge.\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{},"colab_type":"code","execution":{"iopub.execute_input":"2024-01-12T18:27:41.840739Z","iopub.status.busy":"2024-01-12T18:27:41.840312Z","iopub.status.idle":"2024-01-12T18:27:43.088010Z","shell.execute_reply":"2024-01-12T18:27:43.086776Z","shell.execute_reply.started":"2024-01-12T18:27:41.840706Z"},"id":"vWnY8YdR1YMb","trusted":true},"outputs":[],"source":["# Collecting the needed packages\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import string\n","import os\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Embedding\n","from tensorflow.keras.layers import Permute, dot, add, concatenate\n","from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Activation,MaxPooling2D,Bidirectional,Flatten\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n","from tensorflow.keras import optimizers\n","from tensorflow.keras.layers import Layer\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.utils import plot_model\n","from keras.utils import to_categorical\n","from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n","from sklearn.metrics import accuracy_score, f1_score, log_loss, confusion_matrix\n","import spacy\n","sp = spacy.load('en_core_web_sm')"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WTv5Folm5llV"},"source":["## Read Dataset"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"colab_type":"code","execution":{"iopub.execute_input":"2024-01-12T18:27:43.097851Z","iopub.status.busy":"2024-01-12T18:27:43.097445Z","iopub.status.idle":"2024-01-12T18:27:43.179917Z","shell.execute_reply":"2024-01-12T18:27:43.178717Z","shell.execute_reply.started":"2024-01-12T18:27:43.097811Z"},"id":"KkTEILOP1dRn","outputId":"8fb4c9be-960f-4a03-f6b1-98e7cb8e7c1f","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>qid1</th>\n","      <th>qid2</th>\n","      <th>question1</th>\n","      <th>question2</th>\n","      <th>is_duplicate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>What is the step by step guide to invest in sh...</td>\n","      <td>What is the step by step guide to invest in sh...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n","      <td>What would happen if the Indian government sto...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>How can I increase the speed of my internet co...</td>\n","      <td>How can Internet speed be increased by hacking...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>Why am I mentally very lonely? How can I solve...</td>\n","      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>9</td>\n","      <td>10</td>\n","      <td>Which one dissolve in water quikly sugar, salt...</td>\n","      <td>Which fish would survive in salt water?</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  qid1  qid2                                          question1  \\\n","0   0     1     2  What is the step by step guide to invest in sh...   \n","1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n","2   2     5     6  How can I increase the speed of my internet co...   \n","3   3     7     8  Why am I mentally very lonely? How can I solve...   \n","4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n","\n","                                           question2  is_duplicate  \n","0  What is the step by step guide to invest in sh...             0  \n","1  What would happen if the Indian government sto...             0  \n","2  How can Internet speed be increased by hacking...             0  \n","3  Find the remainder when [math]23^{24}[/math] i...             0  \n","4            Which fish would survive in salt water?             0  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# data = pd.read_csv(project_path+\"questions.csv\",nrows=10000)\n","project_path = '/kaggle/input/corpus2/'\n","data = pd.read_csv(project_path+\"questions.csv\",nrows=20000) # the number of rows to be used"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kZr-ay9J5q6E"},"source":["## Preprocess Data"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{},"colab_type":"code","execution":{"iopub.execute_input":"2024-01-12T18:27:43.181776Z","iopub.status.busy":"2024-01-12T18:27:43.181325Z","iopub.status.idle":"2024-01-12T18:27:43.189922Z","shell.execute_reply":"2024-01-12T18:27:43.188937Z","shell.execute_reply.started":"2024-01-12T18:27:43.181742Z"},"id":"sSM_jivf3ZTs","trusted":true},"outputs":[],"source":["# Tokenize, convert to lowercase, remove punctuation, and filter tokens \n","table = str.maketrans('', '', string.punctuation)\n","def clean_question(text): \n","    doc = sp(text)\n","    text = [token.lemma_ for token in doc]\n","    text = [word.lower() for word in text]\n","    text = [w.translate(table) for w in text]\n","    text = [word for word in text if len(word)>1]\n","    text = [word for word in text if word.isalpha()]\n","    return ' '.join(text)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{},"colab_type":"code","execution":{"iopub.execute_input":"2024-01-12T18:27:43.193454Z","iopub.status.busy":"2024-01-12T18:27:43.193083Z","iopub.status.idle":"2024-01-12T18:33:39.628723Z","shell.execute_reply":"2024-01-12T18:33:39.627406Z","shell.execute_reply.started":"2024-01-12T18:27:43.193425Z"},"id":"HXXKfkiY52_y","trusted":true},"outputs":[],"source":["data[\"question1\"] = data[\"question1\"].apply(lambda x:clean_question(x))\n","data[\"question2\"] = data[\"question2\"].apply(lambda x:clean_question(x))"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4S9747qX0ZbP"},"source":["## Feature Extraction\n","To capture semantic meaning, pre-trained GloVe word embeddings are employed. The tokenized and preprocessed question sequences are padded to a fixed length, facilitating effective model training."]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","execution":{"iopub.execute_input":"2024-01-12T18:33:39.648491Z","iopub.status.busy":"2024-01-12T18:33:39.648163Z","iopub.status.idle":"2024-01-12T18:33:40.303177Z","shell.execute_reply":"2024-01-12T18:33:40.302158Z","shell.execute_reply.started":"2024-01-12T18:33:39.648464Z"},"id":"qh20eJmABc_K","outputId":"d473d9ab-d1c7-44dd-d26b-72629ccb1857","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Vocabulary Size: 27022\n"]}],"source":["# fit a tokenizer with questions\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(data[\"question1\"].values+data[\"question2\"].values)\n","vocab_size = len(tokenizer.word_index) + 1\n","print('Vocabulary Size: %d' % vocab_size)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{},"colab_type":"code","execution":{"iopub.execute_input":"2024-01-12T18:33:40.304689Z","iopub.status.busy":"2024-01-12T18:33:40.304379Z","iopub.status.idle":"2024-01-12T18:33:41.530328Z","shell.execute_reply":"2024-01-12T18:33:41.529318Z","shell.execute_reply.started":"2024-01-12T18:33:40.304663Z"},"id":"v7AoYTqeD7y5","trusted":true},"outputs":[],"source":["# create sequences\n","max_len = 25\n","q1_texts_seq = tokenizer.texts_to_sequences(data[\"question1\"].values)\n","q2_texts_seq = tokenizer.texts_to_sequences(data[\"question2\"].values)\n","\n","q1_texts_seq = pad_sequences(q1_texts_seq,maxlen=max_len)\n","q2_texts_seq = pad_sequences(q2_texts_seq,maxlen=max_len)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","execution":{"iopub.execute_input":"2024-01-12T18:33:41.533160Z","iopub.status.busy":"2024-01-12T18:33:41.532365Z","iopub.status.idle":"2024-01-12T18:34:09.103538Z","shell.execute_reply":"2024-01-12T18:34:09.102434Z","shell.execute_reply.started":"2024-01-12T18:33:41.533115Z"},"id":"JDbhWXclJkbP","outputId":"c30e1d79-bc2b-449d-cbc7-2cfa358871e2","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 400000 word vectors.\n"]}],"source":["# Load Glove vectors\n","embeddings_index = {} # empty dictionary\n","f = open(os.path.join(\"/kaggle/input/glove/\", 'glove.6B.200d.txt'), encoding=\"utf-8\")\n","\n","for line in f:\n","    values = line.split()\n","    word = values[0]\n","    coefs = np.asarray(values[1:], dtype='float32')\n","    embeddings_index[word] = coefs\n","f.close()\n","print('Found %s word vectors.' % len(embeddings_index))"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{},"colab_type":"code","execution":{"iopub.execute_input":"2024-01-12T18:34:09.105193Z","iopub.status.busy":"2024-01-12T18:34:09.104866Z","iopub.status.idle":"2024-01-12T18:34:09.190038Z","shell.execute_reply":"2024-01-12T18:34:09.189029Z","shell.execute_reply.started":"2024-01-12T18:34:09.105166Z"},"id":"7CUjZjcCJmiq","trusted":true},"outputs":[],"source":["embedding_dim = 200\n","\n","# Get 200-dim dense vector for each of the 10000 words in out vocabulary\n","embedding_matrix = np.zeros((vocab_size, embedding_dim))\n","\n","for word, i in tokenizer.word_index.items():\n","    #if i < max_words:\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","        # Words not found in the embedding index will be all zeros\n","        embedding_matrix[i] = embedding_vector"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{},"colab_type":"code","execution":{"iopub.execute_input":"2024-01-12T18:34:09.191745Z","iopub.status.busy":"2024-01-12T18:34:09.191376Z","iopub.status.idle":"2024-01-12T18:34:09.201191Z","shell.execute_reply":"2024-01-12T18:34:09.199939Z","shell.execute_reply.started":"2024-01-12T18:34:09.191714Z"},"id":"WfWFaPkLFUu1","trusted":true},"outputs":[],"source":["X = np.stack((q1_texts_seq, q2_texts_seq), axis=1)\n","y = data[\"is_duplicate\"].values"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{},"colab_type":"code","execution":{"iopub.execute_input":"2024-01-12T18:34:09.203941Z","iopub.status.busy":"2024-01-12T18:34:09.203385Z","iopub.status.idle":"2024-01-12T18:34:09.219546Z","shell.execute_reply":"2024-01-12T18:34:09.218382Z","shell.execute_reply.started":"2024-01-12T18:34:09.203892Z"},"id":"wrE_9flOGVCU","trusted":true},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{},"colab_type":"code","execution":{"iopub.execute_input":"2024-01-12T18:34:09.221654Z","iopub.status.busy":"2024-01-12T18:34:09.220931Z","iopub.status.idle":"2024-01-12T18:34:09.228571Z","shell.execute_reply":"2024-01-12T18:34:09.227242Z","shell.execute_reply.started":"2024-01-12T18:34:09.221612Z"},"id":"_V0HpjaGF296","trusted":true},"outputs":[],"source":["# Get Question 1/2  train and test features\n","q1_X_train = X_train[:,0]\n","q2_X_train = X_train[:,1]\n","\n","q1_X_test = X_test[:,0]\n","q2_X_test = X_test[:,1]"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NK-anqJIwxeR"},"source":["## Build Model\n","\n","Lets build **Bidirectional Long Short-Term Memory with Gated Relevance Network** for Paraphrase Detection"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{},"colab_type":"code","execution":{"iopub.execute_input":"2024-01-12T18:34:09.235862Z","iopub.status.busy":"2024-01-12T18:34:09.235355Z","iopub.status.idle":"2024-01-12T18:34:09.258267Z","shell.execute_reply":"2024-01-12T18:34:09.257148Z","shell.execute_reply.started":"2024-01-12T18:34:09.235822Z"},"id":"8rHoUhWuMF3B","trusted":true},"outputs":[],"source":["class GatedRelevanceNetwork(Layer):\n","    def __init__(self, output_dim,\n","            weights_initializer=\"glorot_uniform\",\n","            bias_initializer=\"zeros\", **kwargs):\n","        self.output_dim = output_dim\n","        self.weights_initializer = weights_initializer\n","        self.bias_initializer = bias_initializer\n","        super(GatedRelevanceNetwork, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        batch_size, len1, emb_dim = input_shape[0]\n","        _, len2, _ = input_shape[1]\n","        # Weights initialization\n","        # Bilinear Tensor Product weights\n","        self.Wb = self.add_weight(name='weights_btp',\n","                                  shape=(self.output_dim, emb_dim, emb_dim),\n","                                  initializer=self.weights_initializer,\n","                                  trainable=True)\n","\n","        # Single Layer Network weights\n","        self.Wd = self.add_weight(name='weights_sln',\n","                                  shape=(2*emb_dim, self.output_dim),\n","                                  initializer=self.weights_initializer,\n","                                  trainable=True)\n","\n","        # Gate weights\n","        self.Wg = self.add_weight(name='weights_gate',\n","                                  shape=(2*emb_dim, self.output_dim),\n","                                  initializer=self.weights_initializer,\n","                                  trainable=True)\n","\n","        # Gate bias\n","        self.bg = self.add_weight(name='bias_gate',\n","                                  shape=(self.output_dim,),\n","                                  initializer=self.bias_initializer,\n","                                  trainable=True)\n","\n","        # General bias\n","        self.b = self.add_weight(name='bias',\n","                                 shape=(self.output_dim,),\n","                                 initializer=self.bias_initializer,\n","                                 trainable=True)\n","\n","        # Channel weights\n","        self.u = self.add_weight(name=\"channel_weights\",\n","                                 shape=(self.output_dim, 1),\n","                                 initializer=self.weights_initializer,\n","                                 trainable=True)\n","\n","        super(GatedRelevanceNetwork, self).build(input_shape)\n","\n","    def call(self, x):\n","        e1 = x[0]\n","        e2 = x[1]\n","\n","        batch_size = K.shape(e1)[0]\n","        # Usually len1 = len2 = max_seq_length\n","        _, len1, emb_dim = K.int_shape(e1)\n","        _, len2, _ = K.int_shape(e2)\n","\n","        # Repeating the matrices to generate all the combinations\n","        ne1 = K.reshape(K.repeat_elements(K.expand_dims(e1, axis=2), len2, axis=2),\n","                       (batch_size, len1*len2, emb_dim))\n","        ne2 = K.reshape(K.repeat_elements(K.expand_dims(e2, axis=1), len1, axis=1),\n","                       (batch_size, len1*len2, emb_dim))\n","\n","        # Repeating the second matrix to use in Bilinear Tensor Product\n","        ne2_k = K.repeat_elements(K.expand_dims(ne2, axis=-1), self.output_dim, axis=-1)\n","\n","        # Bilinear tensor product\n","        btp = K.sum(ne2_k * K.permute_dimensions(K.dot(ne1, self.Wb), (0,1,3,2)), axis=2)\n","        btp = K.reshape(btp, (batch_size, len1, len2, self.output_dim))\n","\n","        # Concatenating inputs to apply Single Layer Network\n","        e = K.concatenate([ne1, ne2], axis=-1)\n","\n","        # Single Layer Network\n","        #sln = K.relu(K.dot(e, self.Wd))\n","        sln = K.tanh(K.dot(e, self.Wd))\n","        sln = K.reshape(sln, (batch_size, len1, len2, self.output_dim))\n","\n","        # Gate\n","        g = K.sigmoid(K.dot(e, self.Wg) + self.bg)\n","        g = K.reshape(g, (batch_size, len1, len2, self.output_dim))\n","\n","        # Gated Relevance Network\n","        #s = K.reshape(K.dot(g*btp + (1-g)*sln + self.b, self.u), (batch_size, len1, len2))\n","        s = K.dot(g*btp + (1-g)*sln + self.b, self.u)\n","\n","        return s\n","\n","    def compute_output_shape(self, input_shape):\n","        shape1 = input_shape[0]\n","        shape2 = input_shape[1]\n","        return (shape1[0], shape1[1], shape2[1], 1)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{},"colab_type":"code","execution":{"iopub.execute_input":"2024-01-12T18:34:09.259642Z","iopub.status.busy":"2024-01-12T18:34:09.259295Z","iopub.status.idle":"2024-01-12T18:34:09.278333Z","shell.execute_reply":"2024-01-12T18:34:09.276920Z","shell.execute_reply.started":"2024-01-12T18:34:09.259615Z"},"id":"NzGgSYmZGMaZ","trusted":true},"outputs":[],"source":["def create_model(input_shape,\n","                      embeddings_dim, embeddings_matrix, vocab_size,\n","                      max_seq_length, trainable_embeddings, dropout,\n","                      lstm_hidden_units, attention_channels, pool_size,\n","                      fc_hidden_units):\n","   \n","    X1_input = Input(input_shape, name=\"input_X1\")\n","    X2_input = Input(input_shape, name=\"input_X2\")\n","\n","    # Encoding the inputs using the same weights\n","    # Output shape: (batch_size, max_seq_length, lstm_hidden_units)\n","    embeddor = Embedding(vocab_size,\n","                    embeddings_dim,\n","                    weights=[embeddings_matrix],\n","                    input_length=input_shape[0],\n","                    trainable=trainable_embeddings,\n","                    mask_zero=False)\n","    X1 = embeddor(X1_input)\n","    X2 = embeddor(X2_input)\n","\n","    encoder = Bidirectional(LSTM(lstm_hidden_units, return_sequences=True))\n","\n","    # Output shape: (batch_size, max_seq_length, lstm_hidden_units)\n","    X1_encoded = encoder(X1)\n","    X2_encoded = encoder(X2)\n","\n","    # Attention matrix\n","    # Output shape: (batch_size, max_seq_length, max_seq_length, 1)\n","    X = GatedRelevanceNetwork(attention_channels, name=\"grn\")([X1_encoded, X2_encoded])\n","    #X = BatchNormalization()(X)\n","\n","    # Non-overlapping 2D max pooling\n","    # Output shape: (batch_size, pooled_rows, pooled_cols, 1)\n","    print(\"shape before pool\", X.shape)\n","    X = MaxPooling2D(pool_size=(pool_size, pool_size),\n","                        strides=(pool_size, pool_size),\n","                        padding='valid',\n","                        data_format=\"channels_last\",\n","                        name=\"max_pool\")(X)\n","    X = Flatten()(X)\n","\n","    # Multi-Layer Perceptron\n","    #X = Dropout(dropout)(X)\n","    X = Dense(fc_hidden_units, activation=\"tanh\", name=\"mlp\")(X)\n","    X = Dropout(dropout)(X)\n","    X = Dense(2, activation=\"softmax\", name=\"output\")(X)\n","\n","    model = Model(inputs=[X1_input, X2_input], outputs=X, name=\"GRN_model\")\n","    # Compiling model\n","    #optimizer = optimizers.Adam(lr=0.001)\n","    optimizer = optimizers.RMSprop()\n","    model.compile(optimizer=optimizer,\n","                loss=\"binary_crossentropy\",\n","                metrics=[\"accuracy\"])\n","    return model"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":561},"colab_type":"code","execution":{"iopub.execute_input":"2024-01-12T18:34:09.280857Z","iopub.status.busy":"2024-01-12T18:34:09.280399Z","iopub.status.idle":"2024-01-12T18:34:11.203713Z","shell.execute_reply":"2024-01-12T18:34:11.202585Z","shell.execute_reply.started":"2024-01-12T18:34:09.280816Z"},"id":"FOeFGaEQIYTT","outputId":"2fa849e3-0c49-4818-f214-ecfc5f87d45f","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["shape before pool (None, 25, 25, 1)\n","Model: \"GRN_model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_X1 (InputLayer)       [(None, 25)]                 0         []                            \n","                                                                                                  \n"," input_X2 (InputLayer)       [(None, 25)]                 0         []                            \n","                                                                                                  \n"," embedding (Embedding)       (None, 25, 200)              5404400   ['input_X1[0][0]',            \n","                                                                     'input_X2[0][0]']            \n","                                                                                                  \n"," bidirectional (Bidirection  (None, 25, 100)              100400    ['embedding[0][0]',           \n"," al)                                                                 'embedding[1][0]']           \n","                                                                                                  \n"," grn (GatedRelevanceNetwork  (None, 25, 25, 1)            20806     ['bidirectional[0][0]',       \n"," )                                                                   'bidirectional[1][0]']       \n","                                                                                                  \n"," max_pool (MaxPooling2D)     (None, 8, 8, 1)              0         ['grn[0][0]']                 \n","                                                                                                  \n"," flatten (Flatten)           (None, 64)                   0         ['max_pool[0][0]']            \n","                                                                                                  \n"," mlp (Dense)                 (None, 128)                  8320      ['flatten[0][0]']             \n","                                                                                                  \n"," dropout (Dropout)           (None, 128)                  0         ['mlp[0][0]']                 \n","                                                                                                  \n"," output (Dense)              (None, 2)                    258       ['dropout[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 5534184 (21.11 MB)\n","Trainable params: 129784 (506.97 KB)\n","Non-trainable params: 5404400 (20.62 MB)\n","__________________________________________________________________________________________________\n"]}],"source":["dropout = 0.5\n","trainable_embeddings = False\n","lstm_hidden_units = 50\n","attention_channels = 2\n","pool_size = 3\n","fc_hidden_units = 128\n","use_class_weight = False\n","input_shape = (max_len,)\n","model = create_model(input_shape,\n","                      embedding_dim, embedding_matrix, vocab_size,\n","                      max_len, trainable_embeddings, dropout,\n","                      lstm_hidden_units, attention_channels, pool_size,\n","                      fc_hidden_units)\n","model.summary()"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{},"colab_type":"code","execution":{"iopub.execute_input":"2024-01-12T18:34:11.555307Z","iopub.status.busy":"2024-01-12T18:34:11.554996Z","iopub.status.idle":"2024-01-12T18:34:11.561956Z","shell.execute_reply":"2024-01-12T18:34:11.560848Z","shell.execute_reply.started":"2024-01-12T18:34:11.555270Z"},"id":"y-ziFUgbYdFb","trusted":true},"outputs":[],"source":["reduce_alpha = ReduceLROnPlateau(monitor ='val_loss', factor = 0.2, patience = 1, min_lr = 0.001)\n","# stop traning if there increase in loss\n","callbacks = [reduce_alpha] "]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"colab_type":"code","execution":{"iopub.execute_input":"2024-01-12T18:34:11.564612Z","iopub.status.busy":"2024-01-12T18:34:11.563725Z","iopub.status.idle":"2024-01-12T19:09:40.315458Z","shell.execute_reply":"2024-01-12T19:09:40.314426Z","shell.execute_reply.started":"2024-01-12T18:34:11.564566Z"},"id":"SpfEXkzIJ9Bt","outputId":"1084236f-7b74-40d7-8574-d251795668dc","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","250/250 [==============================] - 79s 287ms/step - loss: 0.6218 - accuracy: 0.6488 - val_loss: 0.6045 - val_accuracy: 0.6790 - lr: 0.0010\n","Epoch 2/30\n","250/250 [==============================] - 65s 260ms/step - loss: 0.5695 - accuracy: 0.6951 - val_loss: 0.5777 - val_accuracy: 0.6875 - lr: 0.0010\n","Epoch 3/30\n","250/250 [==============================] - 70s 279ms/step - loss: 0.5297 - accuracy: 0.7251 - val_loss: 0.5665 - val_accuracy: 0.7025 - lr: 0.0010\n","Epoch 4/30\n","250/250 [==============================] - 70s 279ms/step - loss: 0.4856 - accuracy: 0.7581 - val_loss: 0.5678 - val_accuracy: 0.7023 - lr: 0.0010\n","Epoch 5/30\n","250/250 [==============================] - 73s 290ms/step - loss: 0.4325 - accuracy: 0.7936 - val_loss: 0.5763 - val_accuracy: 0.7197 - lr: 0.0010\n","Epoch 6/30\n","250/250 [==============================] - 70s 278ms/step - loss: 0.3733 - accuracy: 0.8260 - val_loss: 0.6275 - val_accuracy: 0.7038 - lr: 0.0010\n","Epoch 7/30\n","250/250 [==============================] - 69s 276ms/step - loss: 0.3094 - accuracy: 0.8620 - val_loss: 0.7069 - val_accuracy: 0.7070 - lr: 0.0010\n","Epoch 8/30\n","250/250 [==============================] - 70s 279ms/step - loss: 0.2491 - accuracy: 0.8926 - val_loss: 0.8025 - val_accuracy: 0.7138 - lr: 0.0010\n","Epoch 9/30\n","250/250 [==============================] - 70s 281ms/step - loss: 0.1959 - accuracy: 0.9211 - val_loss: 0.9515 - val_accuracy: 0.7088 - lr: 0.0010\n","Epoch 10/30\n","250/250 [==============================] - 69s 277ms/step - loss: 0.1537 - accuracy: 0.9388 - val_loss: 1.1429 - val_accuracy: 0.7032 - lr: 0.0010\n","Epoch 11/30\n","250/250 [==============================] - 70s 279ms/step - loss: 0.1219 - accuracy: 0.9528 - val_loss: 1.2723 - val_accuracy: 0.7032 - lr: 0.0010\n","Epoch 12/30\n","250/250 [==============================] - 70s 280ms/step - loss: 0.0977 - accuracy: 0.9647 - val_loss: 1.5441 - val_accuracy: 0.6890 - lr: 0.0010\n","Epoch 13/30\n","250/250 [==============================] - 69s 277ms/step - loss: 0.0804 - accuracy: 0.9711 - val_loss: 1.7108 - val_accuracy: 0.6917 - lr: 0.0010\n","Epoch 14/30\n","250/250 [==============================] - 70s 280ms/step - loss: 0.0719 - accuracy: 0.9736 - val_loss: 1.7960 - val_accuracy: 0.7035 - lr: 0.0010\n","Epoch 15/30\n","250/250 [==============================] - 69s 277ms/step - loss: 0.0595 - accuracy: 0.9786 - val_loss: 1.8108 - val_accuracy: 0.6988 - lr: 0.0010\n","Epoch 16/30\n","250/250 [==============================] - 69s 278ms/step - loss: 0.0600 - accuracy: 0.9801 - val_loss: 1.9539 - val_accuracy: 0.7075 - lr: 0.0010\n","Epoch 17/30\n","250/250 [==============================] - 70s 279ms/step - loss: 0.0487 - accuracy: 0.9824 - val_loss: 2.0958 - val_accuracy: 0.7085 - lr: 0.0010\n","Epoch 18/30\n","250/250 [==============================] - 69s 277ms/step - loss: 0.0451 - accuracy: 0.9838 - val_loss: 2.2116 - val_accuracy: 0.6955 - lr: 0.0010\n","Epoch 19/30\n","250/250 [==============================] - 70s 278ms/step - loss: 0.0467 - accuracy: 0.9842 - val_loss: 2.1314 - val_accuracy: 0.7023 - lr: 0.0010\n","Epoch 20/30\n","250/250 [==============================] - 69s 277ms/step - loss: 0.0352 - accuracy: 0.9881 - val_loss: 2.3365 - val_accuracy: 0.6973 - lr: 0.0010\n","Epoch 21/30\n","250/250 [==============================] - 69s 277ms/step - loss: 0.0388 - accuracy: 0.9864 - val_loss: 2.4499 - val_accuracy: 0.6940 - lr: 0.0010\n","Epoch 22/30\n","250/250 [==============================] - 69s 278ms/step - loss: 0.0348 - accuracy: 0.9884 - val_loss: 2.5135 - val_accuracy: 0.6995 - lr: 0.0010\n","Epoch 23/30\n","250/250 [==============================] - 72s 286ms/step - loss: 0.0322 - accuracy: 0.9891 - val_loss: 2.6548 - val_accuracy: 0.7038 - lr: 0.0010\n","Epoch 24/30\n","250/250 [==============================] - 69s 278ms/step - loss: 0.0349 - accuracy: 0.9884 - val_loss: 2.6674 - val_accuracy: 0.7042 - lr: 0.0010\n","Epoch 25/30\n","250/250 [==============================] - 74s 294ms/step - loss: 0.0323 - accuracy: 0.9894 - val_loss: 2.7122 - val_accuracy: 0.7072 - lr: 0.0010\n","Epoch 26/30\n","250/250 [==============================] - 72s 290ms/step - loss: 0.0299 - accuracy: 0.9894 - val_loss: 2.5988 - val_accuracy: 0.6955 - lr: 0.0010\n","Epoch 27/30\n","250/250 [==============================] - 75s 300ms/step - loss: 0.0286 - accuracy: 0.9912 - val_loss: 2.6695 - val_accuracy: 0.6900 - lr: 0.0010\n","Epoch 28/30\n","250/250 [==============================] - 73s 291ms/step - loss: 0.0263 - accuracy: 0.9916 - val_loss: 2.6997 - val_accuracy: 0.6908 - lr: 0.0010\n","Epoch 29/30\n","250/250 [==============================] - 73s 293ms/step - loss: 0.0257 - accuracy: 0.9914 - val_loss: 2.8089 - val_accuracy: 0.6913 - lr: 0.0010\n","Epoch 30/30\n","250/250 [==============================] - 71s 284ms/step - loss: 0.0246 - accuracy: 0.9918 - val_loss: 3.0118 - val_accuracy: 0.6802 - lr: 0.0010\n"]}],"source":["epochs = 30\n","batch_size = 64\n","history = model.fit(x=[q1_X_train, q2_X_train],\n","                    y=to_categorical(y_train),\n","                    epochs=epochs,\n","                    batch_size=batch_size,\n","                    validation_data=([q1_X_test, q2_X_test], to_categorical(y_test)),callbacks=callbacks)"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{},"colab_type":"code","execution":{"iopub.execute_input":"2024-01-12T19:09:40.317248Z","iopub.status.busy":"2024-01-12T19:09:40.316917Z","iopub.status.idle":"2024-01-12T19:09:40.407685Z","shell.execute_reply":"2024-01-12T19:09:40.406477Z","shell.execute_reply.started":"2024-01-12T19:09:40.317220Z"},"id":"67_1ZR5mdPGU","trusted":true},"outputs":[],"source":["outputpath = '/kaggle/working/'\n","filepath = outputpath+'model_paraprase_detection_pad.h5'\n","model.save_weights(filepath)"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":136},"colab_type":"code","execution":{"iopub.execute_input":"2024-01-12T19:47:25.640050Z","iopub.status.busy":"2024-01-12T19:47:25.639487Z","iopub.status.idle":"2024-01-12T19:47:45.927483Z","shell.execute_reply":"2024-01-12T19:47:45.926323Z","shell.execute_reply.started":"2024-01-12T19:47:25.640002Z"},"id":"p3C_iFqwdUaM","outputId":"3e2a74c5-0e4a-4587-9ba2-41085e37b6f2","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Evaluation (loss, acc)\n","125/125 [==============================] - 10s 52ms/step - loss: 3.0118 - accuracy: 0.6802\n","125/125 [==============================] - 6s 51ms/step\n","f1 score : 0.6073\n","confusion matrix : \n","[[1732  776]\n"," [ 503  989]]\n"]}],"source":["print(\"Evaluation (loss, acc)\")\n","loss, acc = model.evaluate(x=[q1_X_test, q2_X_test], y=to_categorical(y_test))\n","# print(\"loss: {:.4f}   acc: {:.4f}\".format(loss, acc))\n","pred = np.argmax(model.predict(x=[q1_X_test, q2_X_test]), axis=1)\n","f1 = f1_score(y_test, pred)\n","print(\"f1 score : {:.4f}\".format(f1))\n","print(\"confusion matrix : \")\n","cf_mat = confusion_matrix(y_test, pred)\n","print(cf_mat)"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{},"colab_type":"code","execution":{"iopub.execute_input":"2024-01-12T20:34:43.017034Z","iopub.status.busy":"2024-01-12T20:34:43.016320Z","iopub.status.idle":"2024-01-12T20:34:46.089478Z","shell.execute_reply":"2024-01-12T20:34:46.088375Z","shell.execute_reply.started":"2024-01-12T20:34:43.016995Z"},"id":"ZuOh8yw2vLQZ","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["shape before pool (None, 25, 25, 1)\n","1/1 [==============================] - 2s 2s/step\n","[[1.3725557e-06 9.9999857e-01]]\n","Percentage Predictions: [99.999855]\n","Accuracy: 0.000000\n","F1 Score: 0.000000\n","Confusion Matrix:\n","[[0 1]\n"," [0 0]]\n"]}],"source":["# Testing the model \n","# Import necessary libraries\n","from tensorflow.keras.models import load_model\n","from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n","\n","# Load the saved model\n","model = create_model(input_shape,\n","                      embedding_dim, embedding_matrix, vocab_size,\n","                      max_len, trainable_embeddings, dropout,\n","                      lstm_hidden_units, attention_channels, pool_size,\n","                      fc_hidden_units)\n","\n","model.load_weights(filepath)  # Replace with the actual path\n","\n","# Assume you have a new set of test data in a dictionary format\n","new_test_data_dict = {\n","    'question1': [\"How does photosynthesis work?\", \"What are the benefits of exercise?\", \"Python vs Java\",],\n","    'question2': [\"what is the working mechanism of photosynthesis.\", \"where is the closest supermarket around here?\", \"Comparison between Python and Java\"],\n","    'is_duplicate': [1, 0, 1]  # The true labels (1 for duplicate, 0 for non-duplicate)\n","}\n","\n","# Create a DataFrame\n","new_test_data = pd.DataFrame(new_test_data_dict)\n","\n","# Preprocess the test data (similar to what you did for training data)\n","new_test_data[\"question1\"] = new_test_data[\"question1\"].apply(lambda x: clean_question(x))\n","new_test_data[\"question2\"] = new_test_data[\"question2\"].apply(lambda x: clean_question(x))\n","\n","# Tokenize and pad sequences\n","q1_texts_seq_test = tokenizer.texts_to_sequences(new_test_data[\"question1\"].values)\n","q2_texts_seq_test = tokenizer.texts_to_sequences(new_test_data[\"question2\"].values)\n","\n","q1_texts_seq_test = pad_sequences(q1_texts_seq_test, maxlen=max_len)\n","q2_texts_seq_test = pad_sequences(q2_texts_seq_test, maxlen=max_len)\n","\n","# Assuming 'is_duplicate' is the column with true labels\n","true_labels = new_test_data[\"is_duplicate\"].values\n","print(q1_texts_seq_test)\n","# Make predictions\n","predictions = model.predict([q1_texts_seq_test, q2_texts_seq_test])\n","print(predictions)\n","# Assuming your model outputs probabilities for each class (binary classification)\n","# If you used softmax activation in the output layer, you can use argmax to get the predicted class\n","predicted_labels = np.argmax(predictions, axis=1)\n","\n","# Convert predicted probabilities to percentage values\n","percentage_predictions = predictions[:, 1] * 100  # Assuming index 1 corresponds to the positive class\n","\n","# Print the percentage predictions\n","print(\"Percentage Predictions:\", percentage_predictions)\n","\n","\n","# Evaluate the predictions\n","accuracy = accuracy_score(true_labels, predicted_labels)\n","f1 = f1_score(true_labels, predicted_labels)\n","conf_matrix = confusion_matrix(true_labels, predicted_labels)\n","\n","# Print results with more decimal places\n","print(\"Accuracy: {:.6f}\".format(accuracy))\n","print(\"F1 Score: {:.6f}\".format(f1))\n","print(\"Confusion Matrix:\")\n","print(conf_matrix)\n","\n","def getSimilarity(s1, s2):\n","    cleanedS1 = clean_question(s1)\n","    cleanedS2 = clean_question(s2)\n"]},{"cell_type":"code","execution_count":85,"metadata":{"execution":{"iopub.execute_input":"2024-01-12T21:07:04.036949Z","iopub.status.busy":"2024-01-12T21:07:04.035798Z","iopub.status.idle":"2024-01-12T21:07:04.047807Z","shell.execute_reply":"2024-01-12T21:07:04.046720Z","shell.execute_reply.started":"2024-01-12T21:07:04.036895Z"},"trusted":true},"outputs":[],"source":["import math\n","def getSimilarity(s1, s2):\n","    test_data = {\n","        's1': [s1],\n","        's2': [s2],\n","    }\n","    test_data_frame = pd.DataFrame(test_data)\n","    test_data_frame[\"s1\"] = test_data_frame[\"s1\"].apply(lambda x: clean_question(x))\n","    test_data_frame[\"s2\"] = test_data_frame[\"s2\"].apply(lambda x: clean_question(x))\n","\n","    s1_texts_seq_test = tokenizer.texts_to_sequences(test_data_frame[\"s1\"].values)\n","    s2_texts_seq_test = tokenizer.texts_to_sequences(test_data_frame[\"s2\"].values)\n","\n","    s1_texts_seq_test = pad_sequences(s1_texts_seq_test, maxlen=max_len)\n","    s2_texts_seq_test = pad_sequences(s2_texts_seq_test, maxlen=max_len)\n","\n","    assessment = model.predict([s1_texts_seq_test, s2_texts_seq_test])\n","    assessmentP = assessment[:, 1] * 100\n","    similarity= assessmentP.astype(float)[0]\n","    similarity = math.trunc(similarity*100)/100\n","    lable = \"Not Paraphrase\"\n","    if similarity > 70:\n","        lable = \"Paraphrase\"\n","    return similarity, lable"]},{"cell_type":"code","execution_count":86,"metadata":{"execution":{"iopub.execute_input":"2024-01-12T21:07:10.578650Z","iopub.status.busy":"2024-01-12T21:07:10.578246Z","iopub.status.idle":"2024-01-12T21:07:10.689606Z","shell.execute_reply":"2024-01-12T21:07:10.688494Z","shell.execute_reply.started":"2024-01-12T21:07:10.578619Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 29ms/step\n","Similarity: (99.99, 'Paraphrase')\n"]}],"source":["import math\n","s1 = \"How does photosynthesis work?\"\n","s2 = \"what is the working mechanism of photosynthesis.\"\n","\n","similarity = getSimilarity(s1, s2)\n","print(\"Similarity:\", similarity)"]},{"cell_type":"code","execution_count":87,"metadata":{"execution":{"iopub.execute_input":"2024-01-12T21:07:14.935193Z","iopub.status.busy":"2024-01-12T21:07:14.934769Z","iopub.status.idle":"2024-01-12T21:07:15.046108Z","shell.execute_reply":"2024-01-12T21:07:15.044870Z","shell.execute_reply.started":"2024-01-12T21:07:14.935160Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 31ms/step\n","Similarity: (0.0, 'Not Paraphrase')\n"]}],"source":["s1 = \"What are the benefits of exercise?\"\n","s2 = \"where is the closest supermarket around here?\"\n","\n","similarity = getSimilarity(s1, s2)\n","print(\"Similarity:\", similarity)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Paraphrase_Detection_BiLSTM_GRN.ipynb","provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4287876,"sourceId":7378564,"sourceType":"datasetVersion"},{"datasetId":4287939,"sourceId":7378653,"sourceType":"datasetVersion"}],"dockerImageVersionId":30626,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":4}
